---
title: 피드 포워드(feedforward) 네트워크 *
tags:
  - feedforward
  - 피드포워드

categories:
  - DeepLearning
---

- 제목에 * 표시가 있는 것은 추가할 내용이 있거나 수정할 내용이 있다는 표시입니다.
- 이 글은 김도형 박사님의 <a href="https://datascienceschool.net/">데이터사이언스스쿨</a>의 강의록과 <a href="https://ratsgo.github.io/">이기창님의 ratsgo's blog</a>를 참고하였음을 미리 밝힙니다.

# 피드 포워드(feedforward) 네트워트

피드 포워드 네트워크 함수를 설명하기에 앞서 회귀와 분류의 선형모델을 살펴보고 가겠습니다.

$$y(x,w) = f\left( \sum_{j=1}^M w_j \phi_j(x) \right)$$

위의 수식과 같이 회귀와 분류의 선형모델은 비선형 기저함수 $$\phi_j(x)$$의 선형 결합을 바탕으로 하고 있습니다.

여기서 $$f$$는 분류의 경우는 비선형 활성화 함수고, 회귀의 경우는 항등함수 입니다. 우리의 목표는 이 모델을 확장시켜서 기저 함수 $$\phi_j(x)$$를 매개변수에 종속적이게 만들고 이 매개변수들이 계수 $${w_j}$$와 함께 훈련단계에서 조절되도록 하는 것입니다. 매개 변수적인 비선형 기저 함수를 만드는 데는 여러 방법이 있습니다. 뉴럴 네트워크는 위의 식의 형태를 그대로 따르는 기저 함수를 사용합니다. 각각의 기저 함수는 그 자체가 입력값의 선형 결합들에 대한 비선형 함수이며, 이 때 선형 결합에서의 계수들이 조절 가능한 매개변수입니다.

이를 바탕으로 기본적인 뉴럴 네트워크 모델을 만들어 보겠습니다. 첫번째로 입력변수 $$x_1,...,x_D$$에 대한 선형 결합을 $$M$$개 만들어 보겠습니다.

$$a_j = \sum_{i=1}^D w_{ji}^{(1)} x_i + w_{j0}^{(1)}$$

여기서 $$j=1,...,M$$이며, 위첨자 (1)은 해당 매개변수들이 네트워크의 첫 번째 계층에 해당한다는 것을 나타냅니다. 3장의 명명법에 따라 매개변수 $$w_{ji}^{(1)}$$을 **가중치**라 할 것이고 매개변수 $$w_{j0}^{(1)}$$을 편향(bias)이라 할 것입니다. $$a_j$$는 **활성도**라 한다. 각각의 선형 결합들은 미분 가능한 비선형 **활성화 함수** $$h$$에 의해 변환됩니다.

$$z_j = h(a_j)$$

이 값들은 함수 $$f$$의 기저함수들의 출력값에 해당하는데 뉴럴 네트워크의 맥락에서는 **은닉 유닛** 이라고 합니다. 비선형 함수 $$h$$로는 보통 로지스틱 시그모이드나 'tanh'와 같은 $$s$$자 모양의 함수가 사용됩니다. 이 값들은 다시 함수 $$f$$에 따라 다시 선형 결합되어 **출력 유닛 활성도**를 결과로 냅니다.

$$a_k = \sum_{j=1}^M w_{kj}^{(2)} x_i + w_{k0}^{(2)}$$

여기서 $$k=1,...,K$$이며, $$K$$는 출력값의 총 숫자입니다. 이 변환은 네트워크의 두 번째 계층$$(2)$$에 해당하며, $$w_{k0}^{(2)}$$는 편향 매개변수입니다. 마지막으로 출력 유닛 활성도는 적절한 활성화 함수를 통해 변환되어 네트워크 출력값의 집합 $$y_k$$를 내놓게 됩니다. 활성화 함수 $$h$$는 데이터의 성질과 타깃 변수의 분포에 대한 가정을 바탕으로 선택해야합니다. 표준적인 회귀 문제의 경우에 활성화 함수는 항등함수이며, 이때 $$y_k=a_k$$가 됩니다. 그리고 다중 이진 분류 문제의 경우에는 로지스틱 시그모이드 함수를 이용해서 각각의 출력단위 활성도를 변환하게 됩니다.

$$y_k=\sigma(a_k)$$

$$\sigma(a) = \frac{1}{1+exp(-a)}$$

마지막으로 다중 클래스 문제의 경우에는 소프트맥스 함수가 활성화 함수로 사용됩니다.

지금까지 살펴본 여러 단계들을 합쳐서 전체 네트워크 함수로 표현할수 있습니다. 시그모이드 출력 단위 활성화 함수를 사용할 경우, 다음과 같은 형태를 가지게 됩니다.


$$y(x,w) = \sigma \left( \sum_{j=1}^M w_{kj}^{(2)} h\left( \sum_{i=1}^D w_{ji}^{(1)} x_i + w_{j0}^{(1)}\right) + w_{k0}^{(2)} \right)$$

여기서 모든 가중치와 편향 매개변수들을 벡터 $$w$$로 한데 묶었습니다. 이경우 뉴럴 네트워크 모델은 단순히 입력변수 집합$${x_i}$$을 출력 변수 집합 $${y_k}$$으로 연결하는 비선형 함수가 되며, 이때 이 함수는 조절 가능한 매개변수의 벡터 $$w$$에 따라 결정됩니다.

뉴럴 네트워크 모델과 퍼센트론 모델과의 결정적인 차이는 바로 뉴럴 네트워크 모델은 은닉 유닛에 연속적인 시그모이드 비선형 함수를 사용하는 반면 퍼셉트론 모델은 불연속적인 비선형 계단 함수를 사용한다는 점입니다. 이 이유 때문에 뉴럴 네트워크 함수는 네트워크 매개변수에 대해 미분이 가능합니다. 이 성질은 네트워크 훈련에 있어서 핵심적인 역할을 하게 됩니다. 

