---
title: RNN *
tags:
  - RNN

categories:
  - NaturalLanguageProcessing
---

- 제목에 * 표시가 있는 것은 추가할 내용이 있거나 수정할 내용이 있다는 표시입니다.
- 이 글은 김도형 박사님의 <a href="https://datascienceschool.net/">데이터사이언스스쿨</a>의 강의록과 <a href="https://ratsgo.github.io/">이기창님의 ratsgo's blog</a>를 참고하였음을 미리 밝힙니다.


# RNN

### 일반적인 Neural Networks

`one-to-one` : Vanilla Neural Networks 라고도 불리우며 fixed size의 Input(vector)과 마찬가지로 fixed size의 Output을 가지고 있습니다.

### Recurrent Neural Networks

`one-to-many` : Output에 sequence가 있는 경우이며, Image Captioning 분야에서 쓰이고 있습니다. image를 묘사하는 sequence of words로 출력해 냅니다.

`many to one` : Input에 sequence가 있는 경우이며, Sentiment Classification에 활용되고 있으며, 예를 들어 트위터나 페이스북 등의 sequence of words가 positive한지 negative한지를 분류해 내는 것입니다.

`many to many` : Input과 Output에 모두 sequence가 있는 경우이며, 예를 들어 영어단어로 구성된 문장이 들어왔을때 한국어 단어로 구성된 문장으로 번역한다거나, video Classification이 있을 수 있습니다. 비디오 예측은 frame 하나하나에 대해서 분류를 하게 되는데 현재 시점 뿐만 아니라 지나간 모든 시점에 대해서 예측이 이루어져야 합니다.

<br/>
<center><img data-action="zoom" src='{{ "/assets/img/rnn_01.png" | relative_url }}' alt='absolute'></center>
<br/>
