---
title: CNN *
tags:
  - CNN

categories:
  - DeepLearning
---

- 제목에 * 표시가 있는 것은 추가할 내용이 있거나 수정할 내용이 있다는 표시입니다.
- 이 글은 cs231n 강의 슬라이드를 기반으로 한 <a href="https://www.youtube.com/watch?v=2ngo9-YCxzY&list=PL1Kb3QTCLIVtyOuMgyVgT-OeW0PYXl3j5&index=9">송교석 교수님의 강의</a>, 그리고 <a href="https://ratsgo.github.io/">이기창님의 ratsgo's blog</a>를 참고하였음을 미리 밝힙니다.


# CNN(Convolutional Neural Networks)

 우선 `32 X 32 X 5`의 image가 있다고 가정해보겠습니다. 이렇게 3차원으로 표현된 image는 layer(filter)들을 거치면서 또 다른 volumes of activation을 생성하게 됩니다.
아래 그림을 보면서 설명드리겠습니다.

<br/>
<center><img data-action="zoom" src='{{ "/assets/img/cnn_02.jpg" | relative_url }}' alt='absolute'></center>
<br/>

위 그림에서 확인할 수 있듯이 `32 X 32 X 5`의 image는 `5 X 5 X 3`의 **convolutional filter** 를 거치면서 하나의 volumes of activation을 생성하게 됩니다. convolutional filter는 image의 volumes 공간을 위에서부터 쭉 훑어 나가면서 filter의 크기에 해당하는 image volumes의 chunk를 하나의 숫자로 뽑아 내게 됩니다. 이해가 쉽도록 아래의 gif그림을 보겠습니다.

<br/>
<center><img data-action="zoom" src='{{ "/assets/img/cnn_01.gif" | relative_url }}' alt='absolute'></center>
<center><a href="http://cs231n.github.io/convolutional-networks/">출처</a></center>
<br/>

위 그림처럼 이미지를 convolutional filter가 돌면서 하나의 activation map(convolved feature)을 생성하게 되는 것입니다. 다시 처음 그림으로 돌아와서 설명 드리자면 이렇게 filter를 거친 `32 X 32 X 5` image는 `28 X 28 X 1` activation map을 만들게 됩니다. 이를 응용하면 6개의 convolutional filter는 아래 그림과 같이 6개의 activation map을 만들게 되는 것입니다.

<br/>
<center><img data-action="zoom" src='{{ "/assets/img/cnn_04.jpg" | relative_url }}' alt='absolute'></center>
<br/>

이를 해석하자면 `32 X 32 X 5`의 image를  `28 X 28 X 6`의 새로운 image로 만들었다고 할 수 있습니다. 그리고 이러한 `28 X 28 X 6`의 volumes of activation이 다음 convolutional layer의 input으로 전달되게 되는 것입니다. 이러한 일련의 과정을 도식화하면 아래와 그림과 같이 표현됩니다.

<br/>
<center><img data-action="zoom" src='{{ "/assets/img/cnn_05.jpg" | relative_url }}' alt='absolute'></center>
<br/>


## Convolutional Layer

이제 convolutional filter에 대해서 좀 더 자세히 알아보겠습니다. filter의 개념을 이해하려면 **stride** 와 **pad** 의 개념을 먼저 이해해야 합니다.

먼저 stride의 적용 예시를 보겠습니다. 우선 `7 X 7` input에 `3 X 3` filter를 적용해본다고 가정해봅니다. 그리고 **stride** 를 1이라고 한다면 아래와 같이 움직일 것 입니다.

<br/>
<center><img data-action="zoom" src='{{ "/assets/img/cnn_filter_01.png" | relative_url }}' alt='absolute'></center>

<center><img data-action="zoom" src='{{ "/assets/img/cnn_filter_02.png" | relative_url }}' alt='absolute'></center>
<br/>

그렇다면 **stride** 를 2로 적용한다면 어떻게 움직일까요? 네, 예상하신 바와 같이 아래와 같이 움직일 것입니다.

<br/>
<center><img data-action="zoom" src='{{ "/assets/img/cnn_filter_01.png" | relative_url }}' alt='absolute'></center>

<center><img data-action="zoom" src='{{ "/assets/img/cnn_filter_03.png" | relative_url }}' alt='absolute'></center>
<br/>

이처럼 **stride**는 곧 **stepsize**를 뜻합니다. stride가 1이라면 가로 방향으로 5번, 세로 방향으로 5번 움직일 수 있으므로 output size는 `5 X 5`가 될 것입니다. 마찬가지로 stride가 2라면 가로로 3번, 세로로 3번 움직일 수  있으므로 output size는 `3 X 3`가 될 것입니다.

이 output size를 수식으로 표현한다면 다음과 같습니다.
<br/>
<center><img data-action="zoom" src='{{ "/assets/img/cnn_filter_04.png" | relative_url }}' alt='absolute'></center>
<br/>

$$(N - F) / stride + 1$$

이제는 **pad(zero pad)** 에 대해서 알아보겠습니다. 그림으로 예시를 들자면 `7 X 7`의 input(흰박스 부분)의 테두리에 pad를 두는 것입니다.

<br/>
<center><img data-action="zoom" src='{{ "/assets/img/cnn_filter_05.png" | relative_url }}' alt='absolute'></center>
<br/>

이렇게 **pad** 를 둔다면 output size가 달라지게 됩니다. 위의 공식에 따라 $$N$$이 9가 되고 $$F$$는 3, stride는 1이라고 가정한다면 output size는 `7 X 7`이 나오게 됩니다. 눈치 채셨을 수도 있겠지만, 이처럼 **pad**를 두는 이유는 filter로 인해 사이즈가 급격히 감소되어 정보의 손실이 일어나는 것을 방지하기 위함입니다. 한가지 주의할 점은 pad가 제 기능을 하기 위해서는 pad size를 아래 수식을 사용하여 산출해야합니다.

$$(F-1)/2$$

즉 filter size가 `3 X 3`이라면 pad는 1줄로, filter size가 `5 X 5`라면 pad는 2줄로 두어야 output size가 input size 와 같아지는 효과를 거둘 수 있습니다.


## Pooling Layer

위에서 확인했듯이 convolutional layer에서는 pad를 사용해 size를 보존합니다. 그럼 size 조정은 어디서 하게 될까요? 바로 **pooling layer** 에서 해주게 됩니다. pooling layer의 역할을 이처럼 volume을 작게, 그리고 관리가능하도록 만들어 줍니다.

<br/>
<center><img data-action="zoom" src='{{ "/assets/img/cnn_pooling_01.png" | relative_url }}' alt='absolute'></center>
<br/>

그리고 위 그림처럼 각각의 activation map에 대해서 독립적으로 작용하게 됩니다. 즉 64개의 `224 X 224` activation map에 대해서 독립적으로 pooling layer가 작용하여 64개의 `112 X 112` 로 down sampling된 output을 얻을 수 있습니다.  

pooling의 방법으로는 보통 **MAX pooling 방식** 을 사용합니다.

<br/>
<center><img data-action="zoom" src='{{ "/assets/img/cnn_pooling_02.png" | relative_url }}' alt='absolute'></center>
<br/>

위 그림과 같이 `4 X 4` input을 filter size `2 X 2`, 그리고 stride 2 값으로 MAX pooling 한다면 붉은색 박스안에서 제일 큰 값인 6, 녹색박스에서 제일 큰 값인 8, 노란색박슥에서는 3, 파란색박스에서는 4가 뽑혀 나오게 되어 오른쪽 그림과 같은 output이 나오게 되는 것입니다.

pooling layer의 의도는 결국 네트워크의 파라미터의 개수나 연산량을 줄이기 위해 표현 공간의 사이즈를 줄이는 것입니다. 이 과정을 통해 각 convolutional filter를 거치면서 늘어난 feature의 개수를 줄여 **overfitting** 을 방지하고 특징을 뽑아내게 되어서 **invariance** 한 성질을 얻을 수 있게 된다는 점입니다.


# Fully Connected layer

<br/>
<center><img data-action="zoom" src='{{ "/assets/img/cnn_full_01.png" | relative_url }}' alt='absolute'></center>
<br/>

이렇게 반복적인 convolutional layer와 pooling layer를 거쳐 마지막 Layer 단계인  **Fully Connected layer** 에 도달하게 됩니다(이하 FC layer). 이 layer에서는 input데이터를 column화 시켜서 softmax 함수를 적용시키기 편한 데이터 형태로 바꾸어 줍니다(Flatten). 그리고 softmax 함수를 통해 Classification 하게 됩니다.
